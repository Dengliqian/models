## 一、文件结构说明

### （一）`data_loader.py`

1. **`SafeTrafficDataset` 类**
   - 用于封装数据和标签，支持按序列长度进行索引和切片操作。
   - 初始化时检查数据与标签长度是否一致，序列长度是否大于 0。
   - `__getitem__` 方法根据索引返回指定长度的数据序列和对应的标签。
   - `__len__` 方法返回数据集的长度（考虑序列长度）。

2. **`create_dataloader` 函数**
   - 创建 MindSpore 的 `ds.GeneratorDataset` 数据加载器。
   - 参数包括数据、标签、序列长度、批次大小和是否打乱数据。
   - 根据操作系统和 CPU 核心数，合理设置并行工作进程数。
   - 返回按批次划分的数据加载器。

### （二）`data_preprocessing.py`

1. **`load_nf_bot_iot_data` 函数**
   - 加载 NF-BoT-IoT 数据集文件（Parquet 格式）。
   - 检查数据集中是否包含 “Label” 列。
   - 对标签列进行编码，将文本标签转换为数值标签。
   - 处理特征列，尝试将所有特征转换为数值类型，若无法转换则使用 `LabelEncoder` 进行编码。
   - 使用 `StandardScaler` 对特征数据进行标准化，并将数据和标签转换为 `float32` 类型。
   - 返回处理后的特征数据、标签数据和标签编码器。

### （三）`main.py`

1. **内存监控**
   - 在程序开始时打印初始内存使用情况。

2. **数据加载**
   - 调用 `load_nf_bot_iot_data` 函数加载数据集。
   - 若加载失败，打印错误信息并退出程序。

3. **数据集划分**
   - 使用 `train_test_split` 将数据集划分为训练集、验证集和测试集。
   - 若划分失败，打印错误信息并退出程序。

4. **创建数据加载器**
   - 调用 `create_dataloader` 函数为训练集、验证集和测试集创建数据加载器。
   - 若创建失败，打印错误信息并退出程序。

5. **初始化模型**
   - 创建 `CyberDefenseModel` 模型实例，设置输入维度为训练集特征的维度。
   - 定义损失函数为二元交叉熵损失（`BCELoss`）。
   - 使用 Adam 优化器，学习率为 0.0001。
   - 初始化 `AdaptiveTrainer` 实例。

6. **训练循环**
   - 设置训练轮数为 20 轮。
   - 每轮训练中，模型设置为训练模式，计算每个批次的损失并累加。
   - 每隔 5 轮，调用 `AdaptiveTrainer` 的 `adjust_threshold` 方法调整模型阈值，并在验证集上评估模型性能。
   - 若当前验证集 F1 分数高于最佳 F1 分数，则更新最佳 F1 分数并保存模型检查点。
   - 打印每轮的训练损失和阈值调整后的验证集 F1 分数。

7. **最终测试**
   - 加载最佳模型检查点。
   - 在测试集上评估模型性能，打印准确率、精确率、召回率和 F1 分数。

8. **生成预测结果 CSV 文件**
   - 调用 `generate_predictions_csv` 函数生成预测结果的 CSV 文件。

9. **清理内存**
   - 训练结束后调用 `gc.collect()` 清理内存。

### （四）`model.py`

1. **`CyberDefenseModel` 类**
   - 继承自 MindSpore 的 `nn.Cell`。
   - 构造函数中初始化卷积神经网络（CNN）、长短期记忆网络（LSTM）和全连接层。
   - CNN 部分包含两层卷积和池化操作。
   - LSTM 部分为双向 LSTM，隐藏单元数为 64。
   - 全连接层包含两层，中间使用 ReLU 激活函数。
   - 定义一个阈值参数，默认值为 0.6，不参与梯度更新。
   - `construct` 方法中，先对输入数据进行转置，然后依次通过 CNN、LSTM 和全连接层，最后使用 sigmoid 函数将输出映射到 [0, 1] 区间，并返回预测结果和阈值。

### （五）`train_eval.py`

1. **`AdaptiveTrainer` 类**
   - 初始化时接收模型、损失函数和优化器。
   - 定义 `forward_fn` 方法，用于计算模型的前向传播损失。
   - `adjust_threshold` 方法根据验证集的 F1 分数调整模型阈值，阈值调整公式为：`new_threshold = model.threshold * (1 + 0.1 * (metrics['F1'] - 0.9))`，并使用 `clip_by_value` 方法将阈值限制在 [0.4, 0.7] 范围内。
   - `train_step` 方法用于执行单步训练，计算梯度并更新模型参数。

2. **`evaluate` 函数**
   - 评估模型在指定数据加载器上的性能。
   - 参数包括模型、数据加载器和是否使用模型阈值。
   - 遍历数据加载器，获取模型预测结果，根据阈值将预测结果二值化。
   - 计算混淆矩阵中的 TP、FP、TN 和 FN。
   - 计算准确率、精确率、召回率和 F1 分数，并返回评估指标字典。

3. **`generate_predictions_csv` 函数**
   - 生成预测结果的 CSV 文件。
   - 遍历数据加载器，获取模型预测结果，并使用阈值 0.5 进行二值化。
   - 将预测结果和真实标签转换为原始标签（通过标签编码器的逆变换）。
   - 创建包含真实标签和预测标签的 DataFrame，并保存为 CSV 文件。

## 二、运行环境要求

1. **Python 版本**
   - 建议使用 Python 3.7 及以上版本。

2. **MindSpore 框架**
   - 需要安装 MindSpore 框架，可通过以下命令安装：
     ```bash
     pip install mindspore
     ```

3. **其他依赖库**
   - 需要安装以下依赖库：
     ```bash
     pip install numpy pandas scikit-learn
     ```
     
